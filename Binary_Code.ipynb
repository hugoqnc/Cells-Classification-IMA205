{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hugo Queinnec - IMA205**\n",
    "# Pap smear cells classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports et chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# methods\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#features\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute matthews_correlation_coefficient\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def matthews_correlation_coefficient(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    num = tp * tn - fp * fn\n",
    "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    return num / K.sqrt(den + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of normal: 1302; Number of abnormal: 1619\n"
     ]
    }
   ],
   "source": [
    "# Load Train Data\n",
    "\n",
    "#____ CHANGE WORKING DIRECTORY HERE________________________\n",
    "Working_directory=\"./\"\n",
    "#__________________________________________________________\n",
    "\n",
    "\n",
    "df = pd.read_csv(Working_directory+'metadataTrain.csv') # reading data\n",
    "train_y = df['ABNORMAL'].values # 1 for Melanoma and 0 for healthy\n",
    "class_names = [\"normal\",\"abnormal\"]\n",
    "N=train_y.shape[0]\n",
    "print('Number of normal: {0}; Number of abnormal: {1}'.format((N-np.sum(train_y)), np.sum(train_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Déterminer des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading training images\n",
    "X_labels = df['ID'].values\n",
    "train_img = [0]*N\n",
    "train_imgSegCyt = [0]*N\n",
    "train_imgSegNuc = [0]*N\n",
    "\n",
    "i = 0\n",
    "for id in X_labels:\n",
    "    # defining the image path\n",
    "    image_path = Working_directory+'Train/Train/' + str(id) + '.bmp'\n",
    "    image_pathSegCyt = Working_directory+'Train/Train/' + str(id) + '_segCyt.bmp'\n",
    "    image_pathSegNuc = Working_directory+'Train/Train/' + str(id) + '_segNuc.bmp'\n",
    "\n",
    "    img = imread(image_path)\n",
    "    train_img[i]=img\n",
    "\n",
    "    imgSegCyt = imread(image_pathSegCyt)\n",
    "    train_imgSegCyt[i]=imgSegCyt\n",
    "\n",
    "    imgSegNuc = imread(image_pathSegNuc)\n",
    "    train_imgSegNuc[i]=imgSegNuc\n",
    "\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeManualFeaturesNormalized(img, maskCyt, maskNuc, features, colorFeatures, featuresToNormalize, tupleFeatures):\n",
    "    errorCount = 0\n",
    "\n",
    "    numberOfColorDescriptors = 6\n",
    "    numberOfFeatures = 2*len(features) + numberOfColorDescriptors*len(colorFeatures) + len(featuresToNormalize) + 4*len(tupleFeatures)\n",
    "    \n",
    "\n",
    "    train_img_features = np.zeros((1, numberOfFeatures))\n",
    "\n",
    "    labelsCyt = measure.label(np.round(maskCyt), background=0)\n",
    "    regionsCytR = measure.regionprops(labelsCyt, img[:,:,0])\n",
    "    regionsCytG = measure.regionprops(labelsCyt, img[:,:,1])\n",
    "    regionsCytB = measure.regionprops(labelsCyt, img[:,:,2])\n",
    "\n",
    "    labelsNuc = measure.label(np.round(maskNuc), background=0)\n",
    "    regionsNucR = measure.regionprops(labelsNuc, img[:,:,0])\n",
    "    regionsNucG = measure.regionprops(labelsNuc, img[:,:,1])\n",
    "    regionsNucB = measure.regionprops(labelsNuc, img[:,:,2])\n",
    "\n",
    "    # maskExt = np.int64(255*np.ones((len(maskCyt), len(maskCyt[0]))) - maskCyt - maskNuc)\n",
    "    # labelsExt = measure.label(np.round(maskExt), background=0)\n",
    "    # regionsExtR = measure.regionprops(labelsExt, img[:,:,0])\n",
    "    # regionsExtG = measure.regionprops(labelsExt, img[:,:,1])\n",
    "    # regionsExtB = measure.regionprops(labelsExt, img[:,:,2])\n",
    "\n",
    "    for j in range(len(colorFeatures)):\n",
    "        feature = colorFeatures[j]\n",
    "        if(len(regionsCytR)!=0):\n",
    "            train_img_features[0,j*3] = getattr(regionsCytR[0], feature)\n",
    "            train_img_features[0,j*3+1] = getattr(regionsCytG[0], feature)\n",
    "            train_img_features[0,j*3+2] = getattr(regionsCytB[0], feature)\n",
    "        else:\n",
    "            train_img_features[0,j*3] = None\n",
    "            train_img_features[0,j*3+1] = None\n",
    "            train_img_features[0,j*3+2] = None\n",
    "            errorCount+=1\n",
    "\n",
    "    for j in range(len(colorFeatures)):\n",
    "        feature = colorFeatures[j]\n",
    "        if(len(regionsNucR)!=0):\n",
    "            train_img_features[0,j*3+3*len(colorFeatures)] = getattr(regionsNucR[0], feature)\n",
    "            train_img_features[0,j*3+3*len(colorFeatures)+1] = getattr(regionsNucG[0], feature)\n",
    "            train_img_features[0,j*3+3*len(colorFeatures)+2] = getattr(regionsNucB[0], feature)\n",
    "        else:\n",
    "            train_img_features[0,j*3+3*len(colorFeatures)] = None\n",
    "            train_img_features[0,j*3+3*len(colorFeatures)+1] = None\n",
    "            train_img_features[0,j*3+3*len(colorFeatures)+2] = None\n",
    "            errorCount+=1\n",
    "\n",
    "    # for j in range(len(colorFeatures)):\n",
    "    #     feature = colorFeatures[j]\n",
    "    #     if(len(regionsExtR)!=0):\n",
    "    #         train_img_features[0,j*3+6*len(colorFeatures)+1] = getattr(regionsExtG[0], feature)\n",
    "    #         train_img_features[0,j*3+6*len(colorFeatures)+2] = getattr(regionsExtB[0], feature)\n",
    "    #         train_img_features[0,j*3+6*len(colorFeatures)] = getattr(regionsExtR[0], feature)\n",
    "    #     else:\n",
    "    #         train_img_features[0,j*3+6*len(colorFeatures)] = None\n",
    "    #         train_img_features[0,j*3+6*len(colorFeatures)+1] = None\n",
    "    #         train_img_features[0,j*3+6*len(colorFeatures)+2] = None\n",
    "    #         errorCount+=1\n",
    "    \n",
    "    for j in range(len(featuresToNormalize)):\n",
    "        feature = featuresToNormalize[j]\n",
    "        if(len(regionsCytR)!=0 and len(regionsNucR)!=0 and getattr(regionsCytR[0], feature)!=0):\n",
    "            train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)] = getattr(regionsNucR[0], feature)/getattr(regionsCytR[0], feature)\n",
    "        else:\n",
    "            train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)] = None\n",
    "            #errorCount+=1\n",
    "\n",
    "\n",
    "    for j in range(len(tupleFeatures)):\n",
    "        feature = tupleFeatures[j]\n",
    "        if(len(regionsCytR)!=0 and len(regionsNucR)!=0):\n",
    "            x1,y1 = getattr(regionsCytR[0], feature)\n",
    "            x2,y2 = getattr(regionsNucR[0], feature)\n",
    "            train_img_features[0,j*4+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = x1/y1\n",
    "            train_img_features[0,j*4+1+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = x2/y2\n",
    "            train_img_features[0,j*4+2+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = x1/x2\n",
    "            train_img_features[0,j*4+3+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = y1/y2\n",
    "        else:\n",
    "            train_img_features[0,j*4+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = None\n",
    "            train_img_features[0,j*4+1+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = None\n",
    "            train_img_features[0,j*4+2+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = None\n",
    "            train_img_features[0,j*4+3+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)] = None\n",
    "            #errorCount+=1\n",
    "    \n",
    "    for j in range(len(features)):\n",
    "        feature = features[j]\n",
    "        if feature=='symmetry_lr':\n",
    "            diff_area_h_cyt = np.count_nonzero(maskCyt * ~np.fliplr(maskCyt))\n",
    "            train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)] = diff_area_h_cyt/np.count_nonzero(maskCyt)\n",
    "        elif feature=='symmetry_ud':\n",
    "            diff_area_v_cyt = np.count_nonzero(maskCyt * ~np.flipud(maskCyt))\n",
    "            train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)] = diff_area_v_cyt/np.count_nonzero(maskCyt)\n",
    "        elif feature=='perimeter_norm':\n",
    "            a = getattr(regionsCytR[0], 'minor_axis_length')\n",
    "            p = getattr(regionsCytR[0], 'perimeter')\n",
    "            train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)] = p/a\n",
    "        else:\n",
    "            if(len(regionsCytR)!=0):\n",
    "                train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)] = getattr(regionsCytR[0], feature)\n",
    "            else:\n",
    "                train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)] = None\n",
    "                #errorCount+=1\n",
    "\n",
    "    for j in range(len(features)):\n",
    "        feature = features[j]\n",
    "        if(len(regionsNucR)!=0):\n",
    "            if feature=='symmetry_lr':\n",
    "                diff_area_h_nuc = np.count_nonzero(maskNuc * ~np.fliplr(maskNuc))\n",
    "                train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)+len(features)] = diff_area_h_nuc/np.count_nonzero(maskNuc)\n",
    "            elif feature=='symmetry_ud':\n",
    "                diff_area_v_cyt = np.count_nonzero(maskCyt * ~np.flipud(maskCyt))\n",
    "                train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)+len(features)] = diff_area_v_cyt/np.count_nonzero(maskCyt)\n",
    "            elif feature=='perimeter_norm':\n",
    "                a = getattr(regionsNucR[0], 'minor_axis_length')\n",
    "                p = getattr(regionsNucR[0], 'perimeter')\n",
    "                train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)+len(features)] = p/a\n",
    "            else:\n",
    "               train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)+len(features)] = getattr(regionsNucR[0], feature)\n",
    "        else:\n",
    "            train_img_features[0,j+numberOfColorDescriptors*len(colorFeatures)+len(featuresToNormalize)+4*len(tupleFeatures)+len(features)] = None\n",
    "            #errorCount+=1\n",
    "\n",
    "    \n",
    "\n",
    "    return train_img_features, errorCount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitLinearRegression(train_img_features,train_y):\n",
    "    resolution_param = 150  \n",
    "    regr = LinearRegression()\n",
    "    regr.fit(train_img_features, train_y)\n",
    "    return regr\n",
    "\n",
    "def fitLDA(train_img_features,train_y):\n",
    "    resolution_param = 150  \n",
    "    clf_LDA = LinearDiscriminantAnalysis()\n",
    "    clf_LDA.fit(train_img_features, train_y)\n",
    "    return clf_LDA\n",
    "\n",
    "def fitQDA(train_img_features,train_y):\n",
    "    resolution_param = 150  \n",
    "    clf_QDA = QuadraticDiscriminantAnalysis()\n",
    "    clf_QDA.fit(train_img_features, train_y)\n",
    "    return clf_QDA\n",
    "\n",
    "def fitBayes(train_img_features,train_y):\n",
    "    resolution_param = 150  \n",
    "    clf_GNB = GaussianNB()\n",
    "    clf_GNB.fit(train_img_features, train_y)\n",
    "    return clf_GNB\n",
    "\n",
    "def fitKNN(train_img_features,train_y):\n",
    "    resolution_param = 150  \n",
    "    clf_KNN = KNeighborsClassifier()\n",
    "    clf_KNN.n_neighbors=5\n",
    "    clf_KNN.fit(train_img_features, train_y)\n",
    "    return clf_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prédiction adaptée au splits du training set\n",
    "\n",
    "def predictForTestSplit(one_split_test_img, one_split_test_imgCyt, one_split_test_imgNuc, classifier):\n",
    "    #compute features\n",
    "    f = computeManualFeaturesNormalized(one_split_test_img, one_split_test_imgCyt, one_split_test_imgNuc, features, colorFeatures, featuresToNormalize, tupleFeatures)[0]\n",
    "\n",
    "    for i in range(len(f[0])): #cleaning None values\n",
    "        if np.isnan(f[0][i]):\n",
    "            f[0][i] = meanOfTrainingFeatures[i]\n",
    "\n",
    "    f = scaler.transform(f) #scale\n",
    "\n",
    "    y_test = classifier.predict(f)\n",
    "\n",
    "    return y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEntireTestSplit(split_test_img, split_test_imgSegCyt, split_test_imgSegNuc, classifier):\n",
    "    allFeatures = np.zeros((len(split_test_img), numberOfFeatures))\n",
    "\n",
    "    for i in range(len(split_test_img)):\n",
    "        f = computeManualFeaturesNormalized(split_test_img[i], split_test_imgSegCyt[i], split_test_imgSegNuc[i], features, colorFeatures, featuresToNormalize, tupleFeatures)[0]\n",
    "        \n",
    "        for j in range(len(f[0])): #cleaning None values\n",
    "            if np.isnan(f[0][j]):\n",
    "                f[0][j] = meanOfTrainingFeatures[j]\n",
    "\n",
    "        f = scaler.transform(f) #scale\n",
    "\n",
    "        allFeatures[i,:] = f[0]\n",
    "\n",
    "    \n",
    "    if boolDimensionReduction:\n",
    "        allFeatures = pca.transform(allFeatures)\n",
    "    \n",
    "    y_test = classifier.predict(allFeatures)\n",
    "\n",
    "    return y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_int_round(z, n_class): #for Linear Regression\n",
    "    # rounding needed to go from real to integer values \n",
    "    output = np.round(z).astype(int)\n",
    "    if isinstance(z, np.ndarray):\n",
    "        j = z < 0\n",
    "        output[j] = 0\n",
    "        k = z > n_class - 1\n",
    "        output[k] = n_class - 1\n",
    "    else:\n",
    "        if output < 0:\n",
    "            output = 0\n",
    "        else:\n",
    "            if output > n_class - 1:\n",
    "                output = n_class - 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission csv\n",
    "\n",
    "def submissionCSV(fileName, classifier):\n",
    "\n",
    "    sample = pd.read_csv(Working_directory+'SampleSubmission.csv') # reading data\n",
    "    X_test_values = sample['ID'].values\n",
    "    N = X_test_values.shape[0]\n",
    "\n",
    "    test_img = [0]*N\n",
    "    test_imgSegCyt = [0]*N\n",
    "    test_imgSegNuc = [0]*N\n",
    "\n",
    "    i = 0\n",
    "    for id in X_test_values:\n",
    "        # defining the image path\n",
    "        image_path = Working_directory+'Test/Test/' + str(id) + '.bmp'\n",
    "        image_pathSegCyt = Working_directory+'Test/Test/' + str(id) + '_segCyt.bmp'\n",
    "        image_pathSegNuc = Working_directory+'Test/Test/' + str(id) + '_segNuc.bmp'\n",
    "\n",
    "        img = imread(image_path)\n",
    "        test_img[i]=img\n",
    "\n",
    "        imgSegCyt = imread(image_pathSegCyt)\n",
    "        test_imgSegCyt[i]=imgSegCyt\n",
    "\n",
    "        imgSegNuc = imread(image_pathSegNuc)\n",
    "        test_imgSegNuc[i]=imgSegNuc\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    two_columns = np.zeros((X_test_values.shape[0],2), dtype=int)\n",
    "    two_columns[:,0] = X_test_values\n",
    "\n",
    "    y_prediction = predictEntireTestSplit(test_img, test_imgSegCyt, test_imgSegNuc, classifier)\n",
    "    \n",
    "    for i in range(X_test_values.shape[0]):\n",
    "        two_columns[i,1] = y_prediction[i]\n",
    "\n",
    "    computedValues = pd.DataFrame(two_columns, columns=['ID','ABNORMAL'])\n",
    "    computedValues.to_csv(Working_directory+fileName, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission csv\n",
    "\n",
    "def submissionCSV_MLP(fileName, classifier):\n",
    "\n",
    "    sample = pd.read_csv(Working_directory+'SampleSubmission.csv') # reading data\n",
    "    X_test_values = sample['ID'].values\n",
    "    N = X_test_values.shape[0]\n",
    "\n",
    "    test_img = [0]*N\n",
    "    test_imgSegCyt = [0]*N\n",
    "    test_imgSegNuc = [0]*N\n",
    "\n",
    "    i = 0\n",
    "    for id in X_test_values:\n",
    "        # defining the image path\n",
    "        image_path = Working_directory+'Test/Test/' + str(id) + '.bmp'\n",
    "        image_pathSegCyt = Working_directory+'Test/Test/' + str(id) + '_segCyt.bmp'\n",
    "        image_pathSegNuc = Working_directory+'Test/Test/' + str(id) + '_segNuc.bmp'\n",
    "\n",
    "        img = imread(image_path)\n",
    "        test_img[i]=img\n",
    "\n",
    "        imgSegCyt = imread(image_pathSegCyt)\n",
    "        test_imgSegCyt[i]=imgSegCyt\n",
    "\n",
    "        imgSegNuc = imread(image_pathSegNuc)\n",
    "        test_imgSegNuc[i]=imgSegNuc\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    two_columns = np.zeros((X_test_values.shape[0],2), dtype=int)\n",
    "    two_columns[:,0] = X_test_values\n",
    "\n",
    "    y_prediction = predictEntireTestSplit(test_img, test_imgSegCyt, test_imgSegNuc, classifier)\n",
    "    y_prediction = np.argmax(y_prediction, axis=1)\n",
    "    \n",
    "    for i in range(X_test_values.shape[0]):\n",
    "        two_columns[i,1] = y_prediction[i]\n",
    "\n",
    "    computedValues = pd.DataFrame(two_columns, columns=['ID','ABNORMAL'])\n",
    "    computedValues.to_csv(Working_directory+fileName, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tests\n",
    "On tranforme le train initial en deux ensembles train et test, pour obtenir plus facilement des scores, sans devoir passer par Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____to modify______________________\n",
    "boolSplitAndTestLocally = True #True : the following cells will print Test and Train accuracy | False : the followinf cells will print Train accuracy, and the last cell will export a CSV with the Train predictions of a chosen estimator\n",
    "boolDimensionReduction = False #compute a PCA before Non linear SVM, Boosting and MLP\n",
    "#___________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Set : 1214 ABNORMAL, 976 NORMAL\nTesting Set : 405 ABNORMAL, 326 NORMAL\n"
     ]
    }
   ],
   "source": [
    "# Partage de l'ensemble de test initial\n",
    "\n",
    "if boolSplitAndTestLocally:\n",
    "    split_train_img, split_test_img, split_train_imgSegCyt, split_test_imgSegCyt, split_train_imgSegNuc, split_test_imgSegNuc, split_train_y, split_test_y = train_test_split(train_img, train_imgSegCyt, train_imgSegNuc, train_y, random_state=42, test_size=0.25, stratify=train_y)\n",
    "else:\n",
    "    split_train_img, split_train_imgSegCyt, split_train_imgSegNuc, split_train_y = train_img, train_imgSegCyt, train_imgSegNuc, train_y\n",
    "\n",
    "print(\"Training Set : \"+str(np.sum(split_train_y))+\" ABNORMAL, \"+str(split_train_y.shape[0]-np.sum(split_train_y))+\" NORMAL\")\n",
    "if boolSplitAndTestLocally:\n",
    "    print(\"Testing Set : \"+str(np.sum(split_test_y))+\" ABNORMAL, \"+str(split_test_y.shape[0]-np.sum(split_test_y))+\" NORMAL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul et pre-processing des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Errors in features: 36\n"
     ]
    }
   ],
   "source": [
    "split_N = split_train_y.shape[0]\n",
    "\n",
    "## LOT OF FEATURES\n",
    "# colorFeatures = ['mean_intensity', 'max_intensity', 'min_intensity']\n",
    "# featuresToNormalize = ['area', 'equivalent_diameter', 'perimeter', 'euler_number', 'convex_area', 'minor_axis_length', 'major_axis_length']\n",
    "# tupleFeatures = ['centroid']\n",
    "# features = ['solidity', 'eccentricity', 'extent','symmetry_lr', 'symmetry_ud']#, 'perimeter_norm']\n",
    "\n",
    "\n",
    "## FEW BEST FEATURES\n",
    "colorFeatures = ['mean_intensity', 'max_intensity', 'min_intensity']\n",
    "featuresToNormalize = ['area', 'equivalent_diameter', 'perimeter', 'euler_number']\n",
    "tupleFeatures = ['centroid']\n",
    "features = ['solidity']\n",
    "\n",
    "numberOfFeatures = 2*len(features) + 6*len(colorFeatures) + len(featuresToNormalize) + 4*len(tupleFeatures)\n",
    "train_img_features_0 = np.zeros((split_N, numberOfFeatures))\n",
    "\n",
    "errorCount = 0\n",
    "\n",
    "for i in range(split_N):\n",
    "    img = split_train_img[i]\n",
    "    maskCyt = split_train_imgSegCyt[i]\n",
    "    maskNuc = split_train_imgSegNuc[i]\n",
    "\n",
    "    f, e = computeManualFeaturesNormalized(img, maskCyt, maskNuc, features, colorFeatures, featuresToNormalize, tupleFeatures)\n",
    "    train_img_features_0[i] = f\n",
    "    errorCount+=e\n",
    "\n",
    "print(\"Errors in features: \" + str(errorCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INITIALLY\n",
      "[139.72334326 125.92519197 149.72425656 187.42009132 177.63607306\n",
      " 196.12328767  84.18310502  74.04931507 102.16164384          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan   0.76432367          nan]\n",
      "\n",
      "MEAN\n",
      "All features: (2190, 28) | Features without None: (221, 28)\n",
      "[141.65690285 132.71376483 155.08326071 186.81900452 176.21266968\n",
      " 192.47963801  99.11312217  93.13574661 119.23529412  97.31950815\n",
      "  85.12598488 122.20817908 140.47963801 127.61538462 158.76923077\n",
      "  69.26696833  60.24886878  96.36199095   3.98145325   1.32395347\n",
      "   0.80218177   0.74230769   1.01713392   1.02025948   0.96494403\n",
      "   1.02092981   0.53421701   0.95132065]\n",
      "\n",
      "FINALLY\n",
      "Cleaned features: (2190, 28)\n",
      "[139.72334326 125.92519197 149.72425656 187.42009132 177.63607306\n",
      " 196.12328767  84.18310502  74.04931507 102.16164384  93.14887321\n",
      "  77.93453295 112.33395375 132.76701172 116.81981033 146.77590446\n",
      "  70.88228476  58.21232257  89.99787392   0.65114087   0.5372352\n",
      "   0.31195782   0.74230769   0.9419665    0.9619732    1.02317105\n",
      "   1.02506941   0.76432367   0.96946021]\n"
     ]
    }
   ],
   "source": [
    "def cleanNoneValues(train_img_features_0, verbose):\n",
    "    # replace missing values (None) of train_img_features\n",
    "    if verbose: print(\"INITIALLY\")\n",
    "    m0 = np.mean(train_img_features_0, axis=0)\n",
    "    if verbose: print(m0)\n",
    "\n",
    "    # compute mean of features\n",
    "    if verbose: print(\"\\nMEAN\")\n",
    "    featuresWithoutNone = train_img_features_0[~np.isnan(train_img_features_0).any(axis=1)]\n",
    "    if verbose: print(\"All features: \"+str(train_img_features_0.shape)+\" | Features without None: \"+str(featuresWithoutNone.shape))\n",
    "    m = np.mean(featuresWithoutNone, axis=0)\n",
    "    if verbose: print(m)\n",
    "\n",
    "    #replace missing values\n",
    "    if verbose: print(\"\\nFINALLY\")\n",
    "    train_img_features = np.array([[line[i] if ~np.isnan(line[i]) else m[i] for i in range(len(line))] for line in train_img_features_0])\n",
    "    if verbose: print(\"Cleaned features: \"+str(train_img_features.shape))\n",
    "    m1 = np.mean(train_img_features, axis=0)\n",
    "    if verbose: print(m1)\n",
    "\n",
    "    return train_img_features, m\n",
    "\n",
    "train_img_features, meanOfTrainingFeatures = cleanNoneValues(train_img_features_0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 2.08055922e-16 -1.75221012e-15  7.21866440e-15  4.91235667e-17\n -2.34059347e-16 -3.15830568e-17  2.49977613e-16  2.48989059e-16\n -1.52738045e-16 -1.72791766e-15 -2.73138944e-15  2.89543250e-15\n  6.01117329e-16  5.66099679e-16  1.10434556e-16 -1.33411800e-15\n  3.36653587e-16 -3.15493451e-16  5.83183932e-17  6.24088554e-16\n  2.16381802e-16 -1.70590823e-13 -7.76446386e-16 -5.69012113e-15\n -1.08695397e-14  3.03673880e-15 -1.04295061e-15 -4.12735295e-14]\n"
     ]
    }
   ],
   "source": [
    "# Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_img_features)\n",
    "train_img_features = scaler.transform(train_img_features)\n",
    "\n",
    "m1 = np.mean(train_img_features, axis=0)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes Linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear Regression accuracy: 0.9233926128590971 | Training accuracy: 0.910958904109589\n",
      "LDA accuracy: 0.9233926128590971 | Training accuracy: 0.910958904109589\n",
      "QDA accuracy: 0.8057455540355677 | Training accuracy: 0.8141552511415525\n",
      "Bayes accuracy: 0.7551299589603283 | Training accuracy: 0.7406392694063927\n",
      "KNN accuracy: 0.9192886456908345 | Training accuracy: 0.9552511415525115\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "regr = fitLinearRegression(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "\n",
    "if boolSplitAndTestLocally:\n",
    "    for i in range(split_test_y.shape[0]):\n",
    "        f = computeManualFeaturesNormalized(split_test_img[i], split_test_imgSegCyt[i], split_test_imgSegNuc[i], features, colorFeatures, featuresToNormalize, tupleFeatures)[0]\n",
    "\n",
    "        for i in range(len(f[0])): #cleaning None values\n",
    "            if np.isnan(f[0][i]):\n",
    "                f[0][i] = meanOfTrainingFeatures[i]\n",
    "\n",
    "        f = scaler.transform(f) #scale\n",
    "        split_test_y_predicted.append(class_int_round(regr.predict(f), 2))\n",
    "\n",
    "    print(\"Linear Regression accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted)) + \" | Training accuracy: \"+ str(accuracy_score(split_train_y, class_int_round(regr.predict(train_img_features), 2))))\n",
    "else:\n",
    "    print(\"Linear Regression training accuracy: \"+ str(accuracy_score(split_train_y, class_int_round(regr.predict(train_img_features), 2))))\n",
    "\n",
    "\n",
    "# LDA\n",
    "clf_LDA = fitLDA(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "\n",
    "if boolSplitAndTestLocally:\n",
    "    for i in range(split_test_y.shape[0]):\n",
    "        split_test_y_predicted.append(predictForTestSplit(split_test_img[i], split_test_imgSegCyt[i], split_test_imgSegNuc[i],clf_LDA))\n",
    "\n",
    "    print(\"LDA accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf_LDA.predict(train_img_features))))\n",
    "else:\n",
    "    print(\"LDA training accuracy: \"+ str(accuracy_score(split_train_y, clf_LDA.predict(train_img_features))))\n",
    "\n",
    "\n",
    "# QDA\n",
    "clf_QDA = fitQDA(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "\n",
    "if boolSplitAndTestLocally:\n",
    "    for i in range(split_test_y.shape[0]):\n",
    "        split_test_y_predicted.append(predictForTestSplit(split_test_img[i], split_test_imgSegCyt[i], split_test_imgSegNuc[i],clf_QDA))\n",
    "\n",
    "    print(\"QDA accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf_QDA.predict(train_img_features))))\n",
    "else:\n",
    "    print(\"QDA training accuracy: \"+ str(accuracy_score(split_train_y, clf_QDA.predict(train_img_features))))\n",
    "\n",
    "\n",
    "# Bayes\n",
    "clf_Bayes = fitBayes(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "\n",
    "if boolSplitAndTestLocally:\n",
    "    for i in range(split_test_y.shape[0]):\n",
    "        split_test_y_predicted.append(predictForTestSplit(split_test_img[i], split_test_imgSegCyt[i], split_test_imgSegNuc[i],clf_Bayes))\n",
    "\n",
    "    print(\"Bayes accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf_Bayes.predict(train_img_features))))\n",
    "else:\n",
    "    print(\"Bayes training accuracy: \"+ str(accuracy_score(split_train_y, clf_Bayes.predict(train_img_features))))\n",
    "\n",
    "\n",
    "# QDA\n",
    "clf_KNN = fitKNN(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "\n",
    "if boolSplitAndTestLocally:\n",
    "    for i in range(split_test_y.shape[0]):\n",
    "        split_test_y_predicted.append(predictForTestSplit(split_test_img[i], split_test_imgSegCyt[i], split_test_imgSegNuc[i],clf_KNN))\n",
    "\n",
    "    print(\"KNN accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf_KNN.predict(train_img_features))))\n",
    "else:\n",
    "    print(\"KNN training accuracy: \"+ str(accuracy_score(split_train_y, clf_KNN.predict(train_img_features))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (avant SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features: 28\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features: \" + str(numberOfFeatures)+\"\\n\")\n",
    "train_img_features_reduced = train_img_features\n",
    "\n",
    "if boolDimensionReduction:\n",
    "    print(\"Features size before PCA: \"+str(train_img_features.shape))\n",
    "    pca = PCA(n_components=25, random_state=1)\n",
    "    train_img_features_reduced=pca.fit_transform(train_img_features)\n",
    "    print(\"Features size after PCA: \"+str(train_img_features_reduced.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Non-linear SVM to the training set\n",
      "{'C': 7, 'gamma': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# Looking for the best hyperparameters C and Gamma\n",
    "print(\"Fitting Non-linear SVM to the training set\")\n",
    "cList = [1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,1e1]\n",
    "gammaList = [0.0001, 0.0005, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3]\n",
    "p_grid_nlsvm = {'C': cList,\n",
    "                'gamma': gammaList}\n",
    "NLsvm = SVC(kernel='rbf', probability=True) #use probability=True to make boosting with initialisation bestEstimator\n",
    "grid_nlsvm = GridSearchCV(NLsvm,p_grid_nlsvm,cv=5,scoring=('balanced_accuracy'),return_train_score=True, refit=True, n_jobs=-1) # n_jobs divides computation time by 4 (parallelisation)\n",
    "\n",
    "if boolDimensionReduction:\n",
    "    grid_nlsvm.fit(train_img_features_reduced, split_train_y)\n",
    "else:\n",
    "    grid_nlsvm.fit(train_img_features, split_train_y)\n",
    "\n",
    "print(grid_nlsvm.best_params_)\n",
    "\n",
    "bestEstimator = grid_nlsvm.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NL SVM accuracy: 0.9548563611491108 | Training accuracy: 0.9926940639269406\n"
     ]
    }
   ],
   "source": [
    "split_test_y_predicted = []\n",
    "if boolSplitAndTestLocally:\n",
    "    split_test_y_predicted = predictEntireTestSplit(split_test_img, split_test_imgSegCyt, split_test_imgSegNuc, bestEstimator)\n",
    "\n",
    "    if boolDimensionReduction:\n",
    "        print(\"NL SVM accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, bestEstimator.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"NL SVM accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, bestEstimator.predict(train_img_features))))\n",
    "else:\n",
    "    if boolDimensionReduction:\n",
    "        print(\"NL SVM training accuracy: \"+ str(accuracy_score(split_train_y, bestEstimator.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"NL SVM training accuracy: \"+ str(accuracy_score(split_train_y, bestEstimator.predict(train_img_features))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gradient boosting accuracy: 0.9521203830369357 | Training accuracy: 0.9648401826484019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "if boolDimensionReduction:\n",
    "    clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.1, max_depth=1, random_state=0).fit(train_img_features_reduced, split_train_y)\n",
    "else:\n",
    "    clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.1, max_depth=1, random_state=0).fit(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "if boolSplitAndTestLocally:\n",
    "    split_test_y_predicted = predictEntireTestSplit(split_test_img, split_test_imgSegCyt, split_test_imgSegNuc, clf)\n",
    "\n",
    "    if boolDimensionReduction:\n",
    "        print(\"Gradient boosting accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"Gradient boosting accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features))))\n",
    "else:\n",
    "    if boolDimensionReduction:\n",
    "        print(\"Gradient boosting training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"Gradient boosting training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AdaBoost accuracy: 0.948016415868673 | Training accuracy: 0.989041095890411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "if boolDimensionReduction:\n",
    "    clf = AdaBoostClassifier(n_estimators=500, learning_rate=0.1).fit(train_img_features_reduced, split_train_y)\n",
    "else:\n",
    "    clf = AdaBoostClassifier(n_estimators=2000, learning_rate=0.1).fit(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "if boolSplitAndTestLocally:\n",
    "    split_test_y_predicted = predictEntireTestSplit(split_test_img, split_test_imgSegCyt, split_test_imgSegNuc, clf)\n",
    "\n",
    "    if boolDimensionReduction:\n",
    "        print(\"AdaBoost accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"AdaBoost accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features))))\n",
    "else:\n",
    "    if boolDimensionReduction:\n",
    "        print(\"AdaBoost training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"AdaBoost training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Histogram-Gradient boosting accuracy: 0.9658002735978112 | Training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "if boolDimensionReduction:\n",
    "    clf = HistGradientBoostingClassifier(max_iter=100, l2_regularization=1, learning_rate=0.1).fit(train_img_features_reduced, split_train_y)\n",
    "else:\n",
    "    clf = HistGradientBoostingClassifier(max_iter=100, l2_regularization=0.75, learning_rate=0.1).fit(train_img_features, split_train_y)\n",
    "\n",
    "split_test_y_predicted = []\n",
    "if boolSplitAndTestLocally:\n",
    "    split_test_y_predicted = predictEntireTestSplit(split_test_img, split_test_imgSegCyt, split_test_imgSegNuc, clf)\n",
    "\n",
    "    if boolDimensionReduction:\n",
    "        print(\"Histogram-Gradient boosting accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"Histogram-Gradient boosting accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features))))\n",
    "else:\n",
    "    if boolDimensionReduction:\n",
    "        print(\"Histogram-Gradient boosting training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features_reduced))))\n",
    "    else:\n",
    "        print(\"Histogram-Gradient boosting training accuracy: \"+ str(accuracy_score(split_train_y, clf.predict(train_img_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "print(tf.keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "split_train_y_cat = to_categorical(split_train_y)\n",
    "split_test_y_cat = to_categorical(split_test_y)\n",
    "\n",
    "# number of classes\n",
    "nb_classes = split_train_y_cat.shape[1]\n",
    "print(nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - loss: 0.0117 - matthews_correlation_coefficient: 0.9949\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0114 - matthews_correlation_coefficient: 0.9954\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0074 - matthews_correlation_coefficient: 0.9975\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0084 - matthews_correlation_coefficient: 0.9970\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0052 - matthews_correlation_coefficient: 0.9992\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0097 - matthews_correlation_coefficient: 0.9939\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0186 - matthews_correlation_coefficient: 0.9884\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0139 - matthews_correlation_coefficient: 0.9912\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0335 - matthews_correlation_coefficient: 0.9745\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0116 - matthews_correlation_coefficient: 0.9933\n",
      "Epoch 151/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0069 - matthews_correlation_coefficient: 0.9972\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0249 - matthews_correlation_coefficient: 0.9838\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0090 - matthews_correlation_coefficient: 0.9961\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0117 - matthews_correlation_coefficient: 0.9932\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0239 - matthews_correlation_coefficient: 0.9851\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0133 - matthews_correlation_coefficient: 0.9925\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0094 - matthews_correlation_coefficient: 0.9950\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0071 - matthews_correlation_coefficient: 0.9960\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0101 - matthews_correlation_coefficient: 0.9922\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0117 - matthews_correlation_coefficient: 0.9913\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0167 - matthews_correlation_coefficient: 0.9954\n",
      "Epoch 162/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0156 - matthews_correlation_coefficient: 0.9902\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0182 - matthews_correlation_coefficient: 0.9901\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0118 - matthews_correlation_coefficient: 0.9952\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0270 - matthews_correlation_coefficient: 0.9816\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0162 - matthews_correlation_coefficient: 0.9910\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0103 - matthews_correlation_coefficient: 0.9910\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0163 - matthews_correlation_coefficient: 0.9928\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0101 - matthews_correlation_coefficient: 0.9962\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0119 - matthews_correlation_coefficient: 0.9933\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0054 - matthews_correlation_coefficient: 0.9981\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0230 - matthews_correlation_coefficient: 0.9873\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0349 - matthews_correlation_coefficient: 0.9824\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0372 - matthews_correlation_coefficient: 0.9727\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0142 - matthews_correlation_coefficient: 0.9899\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0089 - matthews_correlation_coefficient: 0.9951\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0598 - matthews_correlation_coefficient: 0.9658\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0469 - matthews_correlation_coefficient: 0.9687\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0530 - matthews_correlation_coefficient: 0.9616\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0594 - matthews_correlation_coefficient: 0.9549\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0447 - matthews_correlation_coefficient: 0.9682\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0596 - matthews_correlation_coefficient: 0.9587\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0358 - matthews_correlation_coefficient: 0.9771\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0186 - matthews_correlation_coefficient: 0.9866\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0339 - matthews_correlation_coefficient: 0.9824\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0385 - matthews_correlation_coefficient: 0.9733\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0233 - matthews_correlation_coefficient: 0.9843\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0249 - matthews_correlation_coefficient: 0.9833\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0304 - matthews_correlation_coefficient: 0.9790\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0361 - matthews_correlation_coefficient: 0.9765\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0331 - matthews_correlation_coefficient: 0.9826\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0163 - matthews_correlation_coefficient: 0.9927\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0340 - matthews_correlation_coefficient: 0.9780\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0331 - matthews_correlation_coefficient: 0.9805\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0224 - matthews_correlation_coefficient: 0.9842\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0303 - matthews_correlation_coefficient: 0.9865\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0283 - matthews_correlation_coefficient: 0.9839\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0339 - matthews_correlation_coefficient: 0.9808\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0193 - matthews_correlation_coefficient: 0.9915\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0148 - matthews_correlation_coefficient: 0.9954\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0181 - matthews_correlation_coefficient: 0.9865\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0254 - matthews_correlation_coefficient: 0.9869\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0121 - matthews_correlation_coefficient: 0.9925\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0255 - matthews_correlation_coefficient: 0.9858\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0149 - matthews_correlation_coefficient: 0.9910\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0126 - matthews_correlation_coefficient: 0.9939\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0061 - matthews_correlation_coefficient: 0.9990\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0079 - matthews_correlation_coefficient: 0.9949\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0089 - matthews_correlation_coefficient: 0.9951\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0106 - matthews_correlation_coefficient: 0.9937\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0168 - matthews_correlation_coefficient: 0.9885\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0555 - matthews_correlation_coefficient: 0.9703\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0179 - matthews_correlation_coefficient: 0.9903\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0080 - matthews_correlation_coefficient: 0.9963\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0062 - matthews_correlation_coefficient: 0.9954\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0273 - matthews_correlation_coefficient: 0.9823\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0259 - matthews_correlation_coefficient: 0.9792\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0138 - matthews_correlation_coefficient: 0.9927\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0151 - matthews_correlation_coefficient: 0.9899\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0154 - matthews_correlation_coefficient: 0.9940\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0086 - matthews_correlation_coefficient: 0.9971\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0103 - matthews_correlation_coefficient: 0.9933\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0155 - matthews_correlation_coefficient: 0.9914\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0268 - matthews_correlation_coefficient: 0.9830\n",
      "Epoch 225/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0134 - matthews_correlation_coefficient: 0.9936\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0092 - matthews_correlation_coefficient: 0.9944\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0233 - matthews_correlation_coefficient: 0.9844\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0145 - matthews_correlation_coefficient: 0.9916\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0183 - matthews_correlation_coefficient: 0.9891\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0189 - matthews_correlation_coefficient: 0.9883\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0101 - matthews_correlation_coefficient: 0.9954\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0076 - matthews_correlation_coefficient: 0.9962\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0145 - matthews_correlation_coefficient: 0.9911\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0260 - matthews_correlation_coefficient: 0.9848\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0343 - matthews_correlation_coefficient: 0.9750\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0132 - matthews_correlation_coefficient: 0.9916\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0324 - matthews_correlation_coefficient: 0.9791\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0227 - matthews_correlation_coefficient: 0.9852\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0135 - matthews_correlation_coefficient: 0.9916\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0196 - matthews_correlation_coefficient: 0.9885\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0317 - matthews_correlation_coefficient: 0.9828\n",
      "Epoch 242/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0147 - matthews_correlation_coefficient: 0.9909\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0321 - matthews_correlation_coefficient: 0.9837\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0261 - matthews_correlation_coefficient: 0.9859\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0284 - matthews_correlation_coefficient: 0.9767\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0091 - matthews_correlation_coefficient: 0.9948\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0058 - matthews_correlation_coefficient: 0.9993\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0117 - matthews_correlation_coefficient: 0.9926\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0042 - matthews_correlation_coefficient: 0.9994\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0041 - matthews_correlation_coefficient: 0.9991\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0056 - matthews_correlation_coefficient: 0.9964\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0289 - matthews_correlation_coefficient: 0.9790\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0408 - matthews_correlation_coefficient: 0.9740\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0191 - matthews_correlation_coefficient: 0.9892\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0356 - matthews_correlation_coefficient: 0.9726\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0131 - matthews_correlation_coefficient: 0.9895\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0144 - matthews_correlation_coefficient: 0.9918\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0130 - matthews_correlation_coefficient: 0.9927\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0168 - matthews_correlation_coefficient: 0.9856\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0270 - matthews_correlation_coefficient: 0.9854\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0202 - matthews_correlation_coefficient: 0.9938\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0261 - matthews_correlation_coefficient: 0.9871\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0456 - matthews_correlation_coefficient: 0.9706\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0156 - matthews_correlation_coefficient: 0.9903\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0112 - matthews_correlation_coefficient: 0.9965\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0122 - matthews_correlation_coefficient: 0.9921\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0084 - matthews_correlation_coefficient: 0.9972\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0114 - matthews_correlation_coefficient: 0.9953\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0092 - matthews_correlation_coefficient: 0.9957\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0242 - matthews_correlation_coefficient: 0.9868\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0082 - matthews_correlation_coefficient: 0.9946\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0283 - matthews_correlation_coefficient: 0.9857\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0094 - matthews_correlation_coefficient: 0.9965\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0317 - matthews_correlation_coefficient: 0.9826\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0329 - matthews_correlation_coefficient: 0.9768\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0150 - matthews_correlation_coefficient: 0.9912\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0194 - matthews_correlation_coefficient: 0.9895\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0117 - matthews_correlation_coefficient: 0.9931\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0084 - matthews_correlation_coefficient: 0.9954\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0117 - matthews_correlation_coefficient: 0.9934\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0095 - matthews_correlation_coefficient: 0.9932\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0127 - matthews_correlation_coefficient: 0.9939\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0100 - matthews_correlation_coefficient: 0.9970\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0108 - matthews_correlation_coefficient: 0.9955\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0050 - matthews_correlation_coefficient: 0.9990\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0141 - matthews_correlation_coefficient: 0.9891\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0171 - matthews_correlation_coefficient: 0.9931\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0052 - matthews_correlation_coefficient: 0.9978\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0074 - matthews_correlation_coefficient: 0.9964\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0049 - matthews_correlation_coefficient: 0.9982\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0099 - matthews_correlation_coefficient: 0.9922\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0234 - matthews_correlation_coefficient: 0.9863\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0139 - matthews_correlation_coefficient: 0.9893\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0174 - matthews_correlation_coefficient: 0.9913\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0270 - matthews_correlation_coefficient: 0.9814\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0292 - matthews_correlation_coefficient: 0.9805\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0206 - matthews_correlation_coefficient: 0.9854\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0316 - matthews_correlation_coefficient: 0.9808\n",
      "Epoch 299/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0095 - matthews_correlation_coefficient: 0.9964\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0109 - matthews_correlation_coefficient: 0.9949\n",
      "Testing\n",
      "MLP accuracy: 0.9616963064295485 | Training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "n_hidden_3 = 256\n",
    "n_hidden_4 = 256\n",
    "n_hidden_5 = 128\n",
    "\n",
    "n_input = train_img_features.shape[1]\n",
    "print(n_input)\n",
    "\n",
    "model_mlp_multi_layer = Sequential()\n",
    "model_mlp_multi_layer.add(Dense(n_hidden_1,input_shape=(n_input,),activation='relu'))\n",
    "model_mlp_multi_layer.add(BatchNormalization())\n",
    "model_mlp_multi_layer.add(Dense(n_hidden_2,input_shape=(n_hidden_1,),activation='relu'))\n",
    "model_mlp_multi_layer.add(BatchNormalization())\n",
    "model_mlp_multi_layer.add(Dense(n_hidden_3,input_shape=(n_hidden_2,),activation='relu'))\n",
    "model_mlp_multi_layer.add(BatchNormalization())\n",
    "model_mlp_multi_layer.add(Dense(n_hidden_4,input_shape=(n_hidden_3,),activation='relu'))\n",
    "model_mlp_multi_layer.add(BatchNormalization())\n",
    "model_mlp_multi_layer.add(Dense(n_hidden_5,input_shape=(n_hidden_4,),activation='relu'))\n",
    "model_mlp_multi_layer.add(BatchNormalization())\n",
    "model_mlp_multi_layer.add(Dense(2,input_shape=(n_hidden_5,),activation='sigmoid')) #softmax for multi layer\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_mlp_multi_layer.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=learning_rate), metrics=[matthews_correlation_coefficient])\n",
    "\n",
    "# Run optimisation algorithm\n",
    "n_epochs = 300\n",
    "batch_size = 84\n",
    "\n",
    "print('Training')\n",
    "model_mlp_multi_layer.fit(train_img_features, split_train_y_cat, epochs=n_epochs,batch_size=batch_size, use_multiprocessing=True) # TO FILL IN\n",
    "\n",
    "print('Testing')\n",
    "split_test_y_predicted = []\n",
    "if boolSplitAndTestLocally:\n",
    "    split_test_y_predicted = predictEntireTestSplit(split_test_img, split_test_imgSegCyt, split_test_imgSegNuc, model_mlp_multi_layer)\n",
    "    split_test_y_predicted = np.argmax(split_test_y_predicted, axis=1)\n",
    "    print(\"MLP accuracy: \"+ str(accuracy_score(split_test_y, split_test_y_predicted))+ \" | Training accuracy: \"+ str(accuracy_score(split_train_y, np.argmax(model_mlp_multi_layer.predict(train_img_features), axis=1))))\n",
    "else:\n",
    "    print(\"MLP training accuracy: \"+ str(accuracy_score(split_train_y, np.argmax(model_mlp_multi_layer.predict(train_img_features), axis=1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV pour Méthodes Linéaires, Non linear SVM ou Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not boolSplitAndTestLocally: #predict test set and export CSV\n",
    "    # to modify ___________\n",
    "    fileName = \"NLSVM.csv\"\n",
    "    classifier = bestEstimator\n",
    "    #______________________\n",
    "\n",
    "    submissionCSV(fileName, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV pour MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not boolSplitAndTestLocally: #predict test set and export CSV\n",
    "    # to modify ___________\n",
    "    fileName = \"MLP.csv\"\n",
    "    classifier = model_mlp_multi_layer\n",
    "    #______________________\n",
    "\n",
    "    submissionCSV_MLP(fileName, classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}